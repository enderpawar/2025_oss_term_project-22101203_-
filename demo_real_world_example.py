"""
ì‹¤ì œ CSV íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì˜ˆì œ
ì‚¬ìš©ìê°€ íŒŒì´í”„ë¼ì¸ ë¹Œë”ì—ì„œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ì½”ë“œì™€ ë™ì¼
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print("="*60)
print("ğŸ¤– ML Pipeline Builder - ì‹¤ì œ ì‘ë™ ë°ëª¨")
print("="*60)

# 1. ìƒ˜í”Œ CSV ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” ì‚¬ìš©ìê°€ ì—…ë¡œë“œ)
print("\nğŸ“ Step 1: ë°ì´í„° ìƒì„± ì¤‘...")
np.random.seed(42)

# ê°€ì§œ ê³ ê° ì´íƒˆ ë°ì´í„° ìƒì„±
n_samples = 1000
data = pd.DataFrame({
    'ë‚˜ì´': np.random.randint(18, 70, n_samples),
    'ì›”_ì‚¬ìš©ì•¡': np.random.randint(10000, 200000, n_samples),
    'ì‚¬ìš©_ê¸°ê°„_ê°œì›”': np.random.randint(1, 120, n_samples),
    'ê³ ê°_ë“±ê¸‰': np.random.choice(['Bronze', 'Silver', 'Gold', 'Platinum'], n_samples),
    'ë¯¼ì›_íšŸìˆ˜': np.random.randint(0, 10, n_samples),
})

# íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± (ì´íƒˆ ì—¬ë¶€)
# ë¯¼ì›ì´ ë§ê³ , ì‚¬ìš©ì•¡ì´ ì ê³ , ê¸°ê°„ì´ ì§§ìœ¼ë©´ ì´íƒˆ í™•ë¥  ë†’ìŒ
churn_prob = (
    (data['ë¯¼ì›_íšŸìˆ˜'] > 5).astype(int) * 0.3 +
    (data['ì›”_ì‚¬ìš©ì•¡'] < 50000).astype(int) * 0.3 +
    (data['ì‚¬ìš©_ê¸°ê°„_ê°œì›”'] < 24).astype(int) * 0.2 +
    np.random.random(n_samples) * 0.2
)
data['ì´íƒˆ'] = (churn_prob > 0.5).astype(int)

# ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
data['ê³ ê°_ë“±ê¸‰_ì½”ë“œ'] = data['ê³ ê°_ë“±ê¸‰'].map({
    'Bronze': 1, 'Silver': 2, 'Gold': 3, 'Platinum': 4
})

print(f"âœ… ë°ì´í„° ìƒì„± ì™„ë£Œ: {data.shape}")
print("\nğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
print(data.head())
print(f"\nì´íƒˆ ë¹„ìœ¨: {data['ì´íƒˆ'].mean():.1%}")

# 2. ë°ì´í„° ë¶„í• 
print("\n" + "="*60)
print("âœ‚ï¸ Step 2: Train/Test Split")
print("="*60)

# íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
X = data[['ë‚˜ì´', 'ì›”_ì‚¬ìš©ì•¡', 'ì‚¬ìš©_ê¸°ê°„_ê°œì›”', 'ê³ ê°_ë“±ê¸‰_ì½”ë“œ', 'ë¯¼ì›_íšŸìˆ˜']]
y = data['ì´íƒˆ']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"âœ… í›ˆë ¨ ë°ì´í„°: {len(X_train)}ê°œ")
print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ")

# 3. ìŠ¤ì¼€ì¼ë§
print("\n" + "="*60)
print("âš–ï¸ Step 3: ë°ì´í„° ìŠ¤ì¼€ì¼ë§")
print("="*60)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"âœ… StandardScaler ì ìš© ì™„ë£Œ")
print(f"   Train shape: {X_train_scaled.shape}")
print(f"   Test shape: {X_test_scaled.shape}")

# 4. ëª¨ë¸ í›ˆë ¨
print("\n" + "="*60)
print("ğŸ“ Step 4: ëª¨ë¸ í›ˆë ¨")
print("="*60)

# ë‘ ê°€ì§€ ëª¨ë¸ ë¹„êµ
models = {
    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),
    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000)
}

results = {}

for name, model in models.items():
    print(f"\nğŸ”„ {name} í›ˆë ¨ ì¤‘...")
    model.fit(X_train_scaled, y_train)
    
    train_score = model.score(X_train_scaled, y_train)
    test_score = model.score(X_test_scaled, y_test)
    
    print(f"   âœ… í›ˆë ¨ ì •í™•ë„: {train_score:.4f}")
    print(f"   âœ… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_score:.4f}")
    
    results[name] = {
        'model': model,
        'train_score': train_score,
        'test_score': test_score
    }

# 5. í‰ê°€
print("\n" + "="*60)
print("ğŸ“Š Step 5: ìƒì„¸ í‰ê°€")
print("="*60)

for name, result in results.items():
    print(f"\n{'='*60}")
    print(f"ğŸ¯ {name} ê²°ê³¼")
    print(f"{'='*60}")
    
    model = result['model']
    y_pred = model.predict(X_test_scaled)
    
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"\nâœ… Accuracy: {accuracy:.4f}")
    print("\nğŸ“‹ Classification Report:")
    print(classification_report(y_test, y_pred, target_names=['ìœ ì§€', 'ì´íƒˆ']))
    print("\nğŸ“Š Confusion Matrix:")
    cm = confusion_matrix(y_test, y_pred)
    print(cm)
    print(f"\ní•´ì„:")
    print(f"  - ì‹¤ì œ ìœ ì§€, ì˜ˆì¸¡ ìœ ì§€: {cm[0][0]}ëª…")
    print(f"  - ì‹¤ì œ ìœ ì§€, ì˜ˆì¸¡ ì´íƒˆ: {cm[0][1]}ëª… (False Positive)")
    print(f"  - ì‹¤ì œ ì´íƒˆ, ì˜ˆì¸¡ ìœ ì§€: {cm[1][0]}ëª… (False Negative)")
    print(f"  - ì‹¤ì œ ì´íƒˆ, ì˜ˆì¸¡ ì´íƒˆ: {cm[1][1]}ëª…")

# 6. íŠ¹ì„± ì¤‘ìš”ë„ (RandomForestë§Œ)
print("\n" + "="*60)
print("ğŸ” Step 6: íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„")
print("="*60)

rf_model = results['RandomForest']['model']
feature_importance = pd.DataFrame({
    'íŠ¹ì„±': X.columns,
    'ì¤‘ìš”ë„': rf_model.feature_importances_
}).sort_values('ì¤‘ìš”ë„', ascending=False)

print("\nğŸ“Š íŠ¹ì„± ì¤‘ìš”ë„ (ë†’ì„ìˆ˜ë¡ ì¤‘ìš”):")
print(feature_importance.to_string(index=False))

# 7. ì‹¤ì œ ì˜ˆì¸¡ ì˜ˆì œ
print("\n" + "="*60)
print("ğŸ”® Step 7: ì‹ ê·œ ê³ ê° ì´íƒˆ ì˜ˆì¸¡")
print("="*60)

# ìƒˆë¡œìš´ ê³ ê° ë°ì´í„°
new_customers = pd.DataFrame({
    'ë‚˜ì´': [25, 45, 60],
    'ì›”_ì‚¬ìš©ì•¡': [30000, 150000, 80000],
    'ì‚¬ìš©_ê¸°ê°„_ê°œì›”': [6, 48, 24],
    'ê³ ê°_ë“±ê¸‰_ì½”ë“œ': [1, 4, 3],
    'ë¯¼ì›_íšŸìˆ˜': [7, 1, 3]
})

print("\nğŸ“ ì˜ˆì¸¡í•  ê³ ê° ì •ë³´:")
print(new_customers)

new_customers_scaled = scaler.transform(new_customers)
predictions = rf_model.predict(new_customers_scaled)
probabilities = rf_model.predict_proba(new_customers_scaled)

print("\nğŸ¯ ì˜ˆì¸¡ ê²°ê³¼:")
for i, (pred, prob) in enumerate(zip(predictions, probabilities)):
    status = "âš ï¸ ì´íƒˆ ìœ„í—˜" if pred == 1 else "âœ… ìœ ì§€ ì˜ˆìƒ"
    print(f"\nê³ ê° {i+1}: {status}")
    print(f"  - ì´íƒˆ í™•ë¥ : {prob[1]:.1%}")
    print(f"  - ìœ ì§€ í™•ë¥ : {prob[0]:.1%}")

# ìµœì¢… ìš”ì•½
print("\n" + "="*60)
print("ğŸ‰ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
print("="*60)
print("\nâœ… ì´ ëª¨ë“  ê³¼ì •ì„ íŒŒì´í”„ë¼ì¸ ë¹Œë”ì—ì„œ")
print("   ë“œë˜ê·¸ ì•¤ ë“œë¡­ë§Œìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
print("\nğŸ“ ìƒì„±ëœ ì½”ë“œ:")
print("   1. ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥")
print("   2. scikit-learn ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ì¤€ìˆ˜")
print("   3. ì´ˆë³´ìë„ ì´í•´ ê°€ëŠ¥í•œ ì£¼ì„")
print("   4. ì‹¤ì „ í”„ë¡œì íŠ¸ ìˆ˜ì¤€ì˜ í’ˆì§ˆ")
print("\nğŸš€ ì§€ê¸ˆ ë°”ë¡œ ì‹œì‘í•˜ì„¸ìš”!")
print("="*60)
